{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bangui/.local/lib/python3.6/site-packages/matplotlib/__init__.py:886: MatplotlibDeprecationWarning: \n",
      "examples.directory is deprecated; in the future, examples will be found relative to the 'datapath' directory.\n",
      "  \"found relative to the 'datapath' directory.\".format(key))\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pkg_resources\n",
    "import seaborn as sns\n",
    "import time\n",
    "import scipy.stats as stats\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'root_directory': './data/benchmark/',\n",
       " 'format_file': '.dill',\n",
       " 'format_model': '.h5',\n",
       " 'root_filename_benchmark': './data/benchmark/df_sample_benchmark_',\n",
       " 'root_filename_model': 'model_jigsaw_',\n",
       " 'n_sample': None,\n",
       " 'n_sample_train': None,\n",
       " 'is_dataset_reloaded': True,\n",
       " 'model_type': 'submission',\n",
       " 'is_model_reloaded': True,\n",
       " 'threshold': 0.5,\n",
       " 'embeddings_dimension': 300,\n",
       " 'val_score_max': True,\n",
       " 'epochs': 10}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import p9_util_benchmark\n",
    "\n",
    "dict_param_benchmark = p9_util_benchmark.dict_param_benchmark.copy()\n",
    "#dict_param_benchmark['n_sample'] = 100000\n",
    "dict_param_benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import p9_util_spacy\n",
    "import p9_util_benchmark\n",
    "#EMBEDDINGS_PATH = '../input/glove-global-vectors-for-word-representation/glove.6B.100d.txt'\n",
    "EMBEDDINGS_PATH = './data/Glove/glove.6B.100d.txt'\n",
    "#EMBEDDINGS_DIMENSION = 100\n",
    "EMBEDDINGS_DIMENSION = 300\n",
    "\n",
    "DROPOUT_RATE = 0.4\n",
    "LEARNING_RATE = 0.00005\n",
    "#LEARNING_RATE = 0.0001\n",
    "NUM_EPOCHS = dict_param_benchmark['epochs']\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "MAX_NUM_WORDS = 10000\n",
    "TOXICITY_COLUMN = 'target'\n",
    "TEXT_COLUMN = 'comment_text'\n",
    "\n",
    "# All comments must be truncated or padded to be the same length.\n",
    "MAX_SEQUENCE_LENGTH = 250\n",
    "#MAX_SEQUENCE_LENGTH = 40\n",
    "\n",
    "THRESHOLD = dict_param_benchmark['threshold']\n",
    "THRESHOLD = 0.5\n",
    "# List all identities\n",
    "identity_columns = [\n",
    "    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n",
    "    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\n",
    "is_batch_norm = False\n",
    "\n",
    "# Convert taget and identity columns to booleans\n",
    "\n",
    "# Convert taget and identity columns to booleans\n",
    "def convert_to_bool(df, col_name):\n",
    "    df[col_name] = np.where(df[col_name] >= THRESHOLD, True, False)\n",
    "    \n",
    "def convert_dataframe_to_bool(df):\n",
    "    bool_df = df.copy()\n",
    "    for col in ['target'] + identity_columns:\n",
    "        convert_to_bool(bool_df, col)\n",
    "    return bool_df\n",
    "def pad_text(texts, tokenizer):\n",
    "    return pad_sequences(tokenizer.texts_to_sequences(texts), maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "\n",
    "def build_embeddings_matrix(tokenizer, dict_param_benchmark) :\n",
    "    \n",
    "    filename_embedding_matrix \\\n",
    "    = p9_util_benchmark.build_filename_embedding_matrix(dict_param_benchmark=dict_param_benchmark)\n",
    "\n",
    "    \n",
    "    if 'benchmark' == dict_param_benchmark['model_type']:\n",
    "        embeddings_path = EMBEDDINGS_PATH\n",
    "    else :\n",
    "        embeddings_path = None\n",
    "        \n",
    "    \n",
    "    \n",
    "    is_dataset_reloaded = dict_param_benchmark['is_dataset_reloaded']\n",
    "    if not is_dataset_reloaded :\n",
    "        embeddings_index = {}\n",
    "        # Load embeddings\n",
    "        if embeddings_path is not None :\n",
    "            print('\\nLoading embeddings...')\n",
    "            with open(embeddings_path) as f:\n",
    "                for line in f:\n",
    "                    values = line.split()\n",
    "                    word = values[0]\n",
    "                    coefs = np.asarray(values[1:], dtype='float32')\n",
    "                    embeddings_index[word] = coefs\n",
    "        else :\n",
    "            # No path to access embeddings.\n",
    "            # Embeddings will be retrieved from Spacy package.\n",
    "            pass\n",
    "        \n",
    "        print('\\nBuilding embeddings matrix...')\n",
    "        embeddings_dimension = dict_param_benchmark['embeddings_dimension']\n",
    "        embedding_matrix = np.zeros((len(tokenizer.word_index) + 1,\n",
    "                                     embeddings_dimension))\n",
    "        num_words_in_embedding = 0\n",
    "        for word, i in tokenizer.word_index.items():\n",
    "            if 0 < len(embeddings_index) :\n",
    "                embedding_vector = embeddings_index.get(word)\n",
    "            else :\n",
    "                embedding_vector = p9_util_spacy.SPACY_LANGUAGE_MODEL(word).vector\n",
    "\n",
    "            if embedding_vector is not None:\n",
    "                num_words_in_embedding += 1\n",
    "                # words not found in embedding index will be all-zeros.\n",
    "                embedding_matrix[i] = embedding_vector\n",
    "                if 0 == i%10000 :\n",
    "                    print(\"\\nVectorized tokens= {} / {}\".format(i, len(tokenizer.word_index)))\n",
    "                else :\n",
    "                    pass\n",
    "            else :\n",
    "                # Vector for this word does not exists; it is skipped.\n",
    "                pass\n",
    "        p5_util.object_dump(embedding_matrix, filename_embedding_matrix, is_verbose=True)\n",
    "    else : \n",
    "        print('\\nLoading embeddings matrix...')\n",
    "        embedding_matrix = p5_util.object_load(filename_embedding_matrix)\n",
    "    \n",
    "    return embedding_matrix\n",
    "    \n",
    "def build_model(train_df, validate_df, tokenizer, embedding_matrix, dict_param_benchmark=None) :\n",
    "    \n",
    "    if dict_param_benchmark is None :\n",
    "        dict_param_benchmark = p9_util_benchmark.dict_param_benchmark.copy()\n",
    "    else :\n",
    "        pass\n",
    "\n",
    "    # Prepare data\n",
    "    train_text = pad_text(train_df[TEXT_COLUMN], tokenizer)\n",
    "    train_labels = to_categorical(train_df[TOXICITY_COLUMN])\n",
    "    validate_text = pad_text(validate_df[TEXT_COLUMN], tokenizer)\n",
    "    validate_labels = to_categorical(validate_df[TOXICITY_COLUMN])\n",
    "    if dict_param_benchmark is None :\n",
    "        is_dataset_reloaded = False \n",
    "    else :\n",
    "        is_dataset_reloaded = dict_param_benchmark['is_dataset_reloaded']\n",
    "    \n",
    "        \n",
    "        \n",
    "    # Create model layers.\n",
    "    def get_convolutional_neural_net_layers(dict_param_benchmark):\n",
    "        \"\"\"Returns (input_layer, output_layer)\"\"\"\n",
    "        if dict_param_benchmark is None :\n",
    "            model_type = 'submission'\n",
    "        else : \n",
    "            model_type = dict_param_benchmark['model_type']\n",
    "\n",
    "        sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "        embeddings_dimension = dict_param_benchmark['embeddings_dimension']\n",
    "        embedding_layer = Embedding(len(tokenizer.word_index) + 1,\n",
    "                                    embeddings_dimension,\n",
    "                                    weights=[embedding_matrix],\n",
    "                                    input_length=MAX_SEQUENCE_LENGTH,\n",
    "                                    trainable=False)\n",
    "        x = embedding_layer(sequence_input)\n",
    "        \n",
    "        if 'submission' ==  model_type :\n",
    "            if is_batch_norm :\n",
    "                x = BatchNormalization()(x)\n",
    "            x = Conv1D(256, 2, activation='relu', padding='same')(x)\n",
    "            x = MaxPooling1D(5, padding='same')(x)\n",
    "\n",
    "            if is_batch_norm :\n",
    "                x = BatchNormalization()(x)\n",
    "            x = Conv1D(256, 3, activation='relu', padding='same')(x)\n",
    "            x = MaxPooling1D(5, padding='same')(x)\n",
    "            \n",
    "            if is_batch_norm :\n",
    "                x = BatchNormalization()(x)\n",
    "            x = Conv1D(256, 4, activation='relu', padding='same')(x)\n",
    "            x = MaxPooling1D(2, padding='same')(x)\n",
    "            if False :\n",
    "                if is_batch_norm :\n",
    "                    x = BatchNormalization()(x)\n",
    "                x = Conv1D(256, 5, activation='relu', padding='same')(x)\n",
    "                x = MaxPooling1D(2, padding='same')(x)\n",
    "\n",
    "                if is_batch_norm :\n",
    "                    x = BatchNormalization()(x)\n",
    "                x = Conv1D(256, 6, strides=1, activation='relu', padding='same')(x)\n",
    "                x = MaxPooling1D(2, padding='same')(x)\n",
    "            \n",
    "            x = Flatten()(x)\n",
    "            if is_batch_norm :\n",
    "                x = BatchNormalization()(x)\n",
    "            x = Dropout(DROPOUT_RATE)(x)\n",
    "            x = Dense(128, activation='relu')(x)\n",
    "            preds = Dense(2, activation='softmax')(x)\n",
    "        elif 'benchmark' == model_type :\n",
    "            x = Conv1D(128, 2, activation='relu', padding='same')(x)\n",
    "            x = MaxPooling1D(5, padding='same')(x)\n",
    "            \n",
    "            x = Conv1D(128, 3, activation='relu', padding='same')(x)\n",
    "            x = MaxPooling1D(5, padding='same')(x)\n",
    "            \n",
    "            x = Conv1D(128, 4, activation='relu', padding='same')(x)\n",
    "            x = MaxPooling1D(40, padding='same')(x)\n",
    "            \n",
    "            x = Flatten()(x)\n",
    "            x = Dropout(DROPOUT_RATE)(x)\n",
    "            x = Dense(128, activation='relu')(x)\n",
    "            preds = Dense(2, activation='softmax')(x)\n",
    "        else :\n",
    "            print(\"\\n*** ERROR : Unknown model type = {}\".format(dict_param_benchmark['model_type']))\n",
    "            return None, None\n",
    "            \n",
    "        return sequence_input, preds\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Compile model.\n",
    "    print('compiling model')\n",
    "    input_layer, output_layer = get_convolutional_neural_net_layers(dict_param_benchmark)\n",
    "    if (input_layer is not None) and (output_layer is not None) :\n",
    "        model = Model(input_layer, output_layer)\n",
    "        model.compile(loss='binary_crossentropy',\n",
    "                      optimizer=RMSprop(lr=LEARNING_RATE),\n",
    "                      metrics=['acc'])\n",
    "        \n",
    "        model.summary()\n",
    "        if dict_param_benchmark['val_score_max'] :\n",
    "            # checkpoint\n",
    "            filepath=p9_util_benchmark.build_filename_model(dict_param_benchmark=dict_param_benchmark)\n",
    "            checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "            list_callback = [checkpoint]\n",
    "        else :\n",
    "            list_callback = None\n",
    "        return train_text, train_labels, validate_text, validate_labels, model, list_callback\n",
    "    else :\n",
    "        print(\"\\n***ERROR : convolutional model building FAILD!\")\n",
    "        return None, None, None, None, None\n",
    "def train_model(train_text, train_labels, validate_text, validate_labels, model,list_callback=None):\n",
    "    # Train model.\n",
    "    val_acc_max = 0.0\n",
    "    print('\\nTraining model...')\n",
    "    \n",
    "    history = model.fit(train_text,\n",
    "              train_labels,\n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=NUM_EPOCHS,\n",
    "              validation_data=(validate_text, validate_labels),\n",
    "              callbacks=list_callback,\n",
    "              verbose=1)\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build file names for model artefacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File name for validation dataset = ./data/benchmark/df_sample_benchmark_valid_300D_FULL.dill\n",
      "\n",
      "File name for train dataset = ./data/benchmark/df_sample_benchmark_train_300D_FULL.dill\n",
      "\n",
      "File name for model = ./data/benchmark/model_jigsaw_submission_sampleFULL_threshold0.5_best.h5\n",
      "\n",
      "File name for tokenizer = ./data/benchmark/tokenizer_FULL.dill\n",
      "\n",
      "File name for embeddings matrix = ./data/benchmark/embedding_matrix_300D_FULL.dill\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "import p5_util\n",
    "import p9_util_benchmark\n",
    "\n",
    "#filename = './data/benchmark/model_jigsaw_benchmark.h5'\n",
    "\n",
    "#--------------------------------------------------------------------\n",
    "# Get configuration for train and validation dataset size.\n",
    "#--------------------------------------------------------------------\n",
    "n_sample = dict_param_benchmark['n_sample']\n",
    "n_sample_train = dict_param_benchmark['n_sample_train']\n",
    "\n",
    "#--------------------------------------------------------------------\n",
    "# Build filename for validatation dataset\n",
    "#--------------------------------------------------------------------\n",
    "filename_benchmark = p9_util_benchmark.build_filename_benchmark(dict_param_benchmark=dict_param_benchmark)\n",
    "print(\"\\nFile name for validation dataset = {}\".format(filename_benchmark))\n",
    "\n",
    "#--------------------------------------------------------------------\n",
    "# Build filename for train dataset\n",
    "#--------------------------------------------------------------------\n",
    "filename_benchmark_train = p9_util_benchmark.build_filename_benchmark(dict_param_benchmark=dict_param_benchmark, is_train=True)\n",
    "print(\"\\nFile name for train dataset = {}\".format(filename_benchmark_train))\n",
    "\n",
    "#--------------------------------------------------------------------\n",
    "# Build filename for benchmark model\n",
    "#--------------------------------------------------------------------\n",
    "filename_model = p9_util_benchmark.build_filename_model(dict_param_benchmark=dict_param_benchmark)\n",
    "print(\"\\nFile name for model = {}\".format(filename_model))\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------\n",
    "# Build filename for Tokenizer\n",
    "#--------------------------------------------------------------------\n",
    "filename_tokenizer = p9_util_benchmark.build_filename_tokenizer(dict_param_benchmark=dict_param_benchmark)\n",
    "print(\"\\nFile name for tokenizer = {}\".format(filename_tokenizer))\n",
    "\n",
    "#--------------------------------------------------------------------\n",
    "# Build filename for matrix of embeddings\n",
    "#--------------------------------------------------------------------\n",
    "filename_embedding = p9_util_benchmark.build_filename_embedding_matrix(dict_param_benchmark=dict_param_benchmark)\n",
    "print(\"\\nFile name for embeddings matrix = {}\".format(filename_embedding))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reload dataset / build dataset along with tokenizer and embeddings matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load configuration file previoulsy used for building dataset, tokenizer and embeddings matrix\n",
    "\n",
    "    Then update flag is_dataset_reload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p5_util.object_load : fileName= ./data/benchmark/df_sample_benchmark_train_300D_FULL.dill\n",
      "p5_util.object_load : fileName= ./data/benchmark/df_sample_benchmark_valid_300D_FULL.dill\n",
      "p5_util.object_load : fileName= ./data/benchmark/tokenizer_FULL.dill\n",
      "p5_util.object_load : fileName= ./data/benchmark/embedding_matrix_300D_FULL.dill\n"
     ]
    }
   ],
   "source": [
    "import p5_util\n",
    "if dict_param_benchmark['is_dataset_reloaded'] :\n",
    "    df_train         = p5_util.object_load(filename_benchmark_train, is_verbose = True) \n",
    "    df_validate      = p5_util.object_load(filename_benchmark, is_verbose = True) \n",
    "    tokenizer        = p5_util.object_load(filename_tokenizer, is_verbose = True) \n",
    "    embedding_matrix = p5_util.object_load(filename_embedding, is_verbose = True) \n",
    "else :\n",
    "    #------------------------------------------------------------\n",
    "    # Build and train benchmark model issued from Kaggle kernel\n",
    "    # benchmark.\n",
    "    #------------------------------------------------------------\n",
    "    print(\"\\nLoad dataset...\")\n",
    "    df_train = pd.read_csv('./data/train.csv.zip', compression='zip', header=0, sep=',', quotechar='\"')\n",
    "    df_train['comment_text'] = df_train['comment_text'].apply(lambda x : x.lower())\n",
    "    df_train['comment_text'] = df_train['comment_text'].astype(str)\n",
    "    \n",
    "\n",
    "    n_sample_train = p9_util_benchmark.dict_param_benchmark['n_sample_train']\n",
    "    if n_sample_train is None :\n",
    "        print(\"\\nBenchmark model is trained with ALL comments from train dataset\")\n",
    "    else :\n",
    "        df_train = df_train.sample(n_sample_train)\n",
    "        print(\"\\nBenchmark model is trained with {} comments from train dataset\".format(n_sample_train))\n",
    "\n",
    "    #------------------------------------------------------------\n",
    "    # Convert model for binay classification\n",
    "    #------------------------------------------------------------\n",
    "    df_train = convert_dataframe_to_bool(df_train)\n",
    "\n",
    "    #------------------------------------------------------------\n",
    "    # Split dataset as train and validation dataset.\n",
    "    #------------------------------------------------------------\n",
    "    df_train, df_validate = model_selection.train_test_split(df_train, test_size=0.2)\n",
    "    print('%d train comments, %d validate comments' % (len(df_train), len(df_validate)))\n",
    "\n",
    "    #------------------------------------------------------------\n",
    "    # Update validation samples count.\n",
    "    #------------------------------------------------------------\n",
    "    n_sample = len(df_validate)\n",
    "    dict_param_benchmark['n_sample'] = n_sample   \n",
    "    \n",
    "    \n",
    "    \n",
    "    #------------------------------------------------------------\n",
    "    # Build Tokenizer\n",
    "    #------------------------------------------------------------\n",
    "    tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "    tokenizer.fit_on_texts(df_train[TEXT_COLUMN])\n",
    "        \n",
    "    #------------------------------------------------------------\n",
    "    # Build embedding matrix\n",
    "    #------------------------------------------------------------\n",
    "    embedding_matrix = build_embeddings_matrix(tokenizer, dict_param_benchmark)    \n",
    "\n",
    "    #--------------------------------------------------------------------\n",
    "    # Save embedding matrix\n",
    "    #--------------------------------------------------------------------\n",
    "    filename_embedding = p9_util_benchmark.build_filename_embedding_matrix(dict_param_benchmark=dict_param_benchmark)\n",
    "    p5_util.object_dump(embedding_matrix,filename_embedding, is_verbose=True )\n",
    "    \n",
    "\n",
    "    #--------------------------------------------------------------------\n",
    "    # Save train dataset\n",
    "    #--------------------------------------------------------------------\n",
    "    filename_benchmark_train = p9_util_benchmark.build_filename_benchmark(dict_param_benchmark=dict_param_benchmark, is_train=True)\n",
    "    p5_util.object_dump(df_train,filename_benchmark_train, is_verbose=True )\n",
    "    \n",
    "    #------------------------------------------------------------\n",
    "    # Save validation dataset; this validation dataset will be \n",
    "    # used by submition model in order to compare both models \n",
    "    # performances.\n",
    "    #------------------------------------------------------------\n",
    "    filename_benchmark = p9_util_benchmark.build_filename_benchmark(dict_param_benchmark=dict_param_benchmark)\n",
    "    p5_util.object_dump(df_validate.sample(n_sample),filename_benchmark, is_verbose=True )\n",
    "\n",
    "    \n",
    "    #------------------------------------------------------------\n",
    "    # Save tokenizer\n",
    "    #------------------------------------------------------------\n",
    "    filename_tokenizer = p9_util_benchmark.build_filename_tokenizer(dict_param_benchmark=dict_param_benchmark)\n",
    "    p5_util.object_dump(tokenizer,filename_tokenizer, is_verbose=True)\n",
    "    \n",
    "    #------------------------------------------------------------\n",
    "    # Save configuration\n",
    "    # When going to this sequences, then is_dataset_reloaded flag\n",
    "    # is fixed to True.\n",
    "    # This allows to use parameters in a mode where dataset  is \n",
    "    # reloaded rather then rebuilt.\n",
    "    #------------------------------------------------------------\n",
    "    dict_param_benchmark['is_dataset_reloaded'] = True\n",
    "    filename_param = p9_util_benchmark.build_filename_param(dict_param_benchmark=dict_param_benchmark)\n",
    "    p5_util.object_dump(dict_param_benchmark,filename_param, is_verbose=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(352897, 300)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'root_directory': './data/benchmark/',\n",
       " 'format_file': '.dill',\n",
       " 'format_model': '.h5',\n",
       " 'root_filename_benchmark': './data/benchmark/df_sample_benchmark_',\n",
       " 'root_filename_model': 'model_jigsaw_',\n",
       " 'n_sample': None,\n",
       " 'n_sample_train': None,\n",
       " 'is_dataset_reloaded': True,\n",
       " 'model_type': 'submission',\n",
       " 'is_model_reloaded': True,\n",
       " 'threshold': 0.5,\n",
       " 'embeddings_dimension': 300,\n",
       " 'val_score_max': True,\n",
       " 'epochs': 10}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_param_benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data/benchmark/model_jigsaw_submission_sampleFULL_threshold0.5_best.h5'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1014 23:05:58.401522 139914000693056 deprecation_wrapper.py:119] From /home/bangui/anaconda3/envs/python36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1014 23:05:58.492946 139914000693056 deprecation_wrapper.py:119] From /home/bangui/anaconda3/envs/python36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:131: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1014 23:05:58.493691 139914000693056 deprecation_wrapper.py:119] From /home/bangui/anaconda3/envs/python36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W1014 23:05:58.520922 139914000693056 deprecation_wrapper.py:119] From /home/bangui/anaconda3/envs/python36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1014 23:05:58.538536 139914000693056 deprecation_wrapper.py:119] From /home/bangui/anaconda3/envs/python36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1014 23:05:58.884912 139914000693056 deprecation.py:506] From /home/bangui/anaconda3/envs/python36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1014 23:05:59.070229 139914000693056 deprecation_wrapper.py:119] From /home/bangui/anaconda3/envs/python36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W1014 23:05:59.508447 139914000693056 deprecation_wrapper.py:119] From /home/bangui/anaconda3/envs/python36/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1014 23:05:59.514635 139914000693056 deprecation.py:323] From /home/bangui/anaconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 105, 300)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 105, 300)          1200      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 105, 256)          153856    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 21, 256)           1024      \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 21, 256)           196864    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 5, 256)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 5, 256)            1024      \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 5, 256)            262400    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 3, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 768)               3072      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               98432     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 718,130\n",
      "Trainable params: 714,970\n",
      "Non-trainable params: 3,160\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "if not dict_param_benchmark['is_model_reloaded'] :\n",
    "    #------------------------------------------------------------\n",
    "    # Train benchmark model\n",
    "    #------------------------------------------------------------\n",
    "    train_text, train_labels, validate_text, validate_labels, model,list_callback =\\\n",
    "    build_model(df_train, df_validate, tokenizer, embedding_matrix, \\\n",
    "                dict_param_benchmark=dict_param_benchmark) \n",
    "\n",
    "    #------------------------------------------------------------\n",
    "    # Save benchmark model\n",
    "    #------------------------------------------------------------\n",
    "    if False :\n",
    "        if model is not None :\n",
    "            model.save(filename_model)    \n",
    "        else :\n",
    "            pass\n",
    "else :\n",
    "    #-------------------------------------------------------------\n",
    "    # Load benchmark model.\n",
    "    #-------------------------------------------------------------\n",
    "    print(\"\\nLoading model...\")\n",
    "    model = keras.models.load_model(filename_model)\n",
    "    model.summary()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model...\n",
      "Train on 1443899 samples, validate on 360975 samples\n",
      "Epoch 1/10\n",
      "1443899/1443899 [==============================] - 2708s 2ms/step - loss: 0.1678 - acc: 0.9402 - val_loss: 0.1538 - val_acc: 0.9446\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.94462, saving model to ./data/benchmark/model_jigsaw_submission_sampleFULL_threshold0.5_best.h5\n",
      "Epoch 2/10\n",
      "1443899/1443899 [==============================] - 3222s 2ms/step - loss: 0.1480 - acc: 0.9465 - val_loss: 0.1561 - val_acc: 0.9435\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.94462\n",
      "Epoch 3/10\n",
      "1443899/1443899 [==============================] - 2943s 2ms/step - loss: 0.1446 - acc: 0.9478 - val_loss: 0.1436 - val_acc: 0.9477\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.94462 to 0.94774, saving model to ./data/benchmark/model_jigsaw_submission_sampleFULL_threshold0.5_best.h5\n",
      "Epoch 4/10\n",
      "1443899/1443899 [==============================] - 2727s 2ms/step - loss: 0.1415 - acc: 0.9487 - val_loss: 0.1493 - val_acc: 0.9483\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.94774 to 0.94829, saving model to ./data/benchmark/model_jigsaw_submission_sampleFULL_threshold0.5_best.h5\n",
      "Epoch 5/10\n",
      "1443899/1443899 [==============================] - 2899s 2ms/step - loss: 0.1394 - acc: 0.9494 - val_loss: 0.1461 - val_acc: 0.9479\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.94829\n",
      "Epoch 6/10\n",
      "1443899/1443899 [==============================] - 3005s 2ms/step - loss: 0.1379 - acc: 0.9499 - val_loss: 0.1447 - val_acc: 0.9482\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.94829\n",
      "Epoch 7/10\n",
      "1443899/1443899 [==============================] - 2971s 2ms/step - loss: 0.1365 - acc: 0.9502 - val_loss: 0.1555 - val_acc: 0.9468\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.94829\n",
      "Epoch 8/10\n",
      "1443899/1443899 [==============================] - 2898s 2ms/step - loss: 0.1352 - acc: 0.9507 - val_loss: 0.1460 - val_acc: 0.9474\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.94829\n",
      "Epoch 9/10\n",
      "1443899/1443899 [==============================] - 2545s 2ms/step - loss: 0.1336 - acc: 0.9510 - val_loss: 0.1484 - val_acc: 0.9470\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.94829\n",
      "Epoch 10/10\n",
      "1443899/1443899 [==============================] - 2374s 2ms/step - loss: 0.1325 - acc: 0.9512 - val_loss: 0.1504 - val_acc: 0.9480\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.94829\n"
     ]
    }
   ],
   "source": [
    "import p5_util\n",
    "model, history = train_model(train_text, train_labels, validate_text, validate_labels, \\\n",
    "                             model,list_callback=list_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 250, 300)          53891100  \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 250, 256)          153856    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 50, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 50, 256)           196864    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 10, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 10, 256)           262400    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 5, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               163968    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 54,668,446\n",
      "Trainable params: 777,346\n",
      "Non-trainable params: 53,891,100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import p5_util\n",
    "import p9_util_benchmark\n",
    "\n",
    "filename= p9_util_benchmark.build_filename_model(dict_param_benchmark=dict_param_benchmark)\n",
    "filename = './data/benchmark/model_jigsaw_submission_sample500000_threshold0.5_best.h5'\n",
    "model = keras.models.load_model(filename)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p5_util.object_load : fileName= ./data/benchmark/df_sample_benchmark_valid_300D_FULL.dill\n"
     ]
    }
   ],
   "source": [
    "df_validate      = p5_util.object_load(filename_benchmark, is_verbose = True) \n",
    "df_validate = df_validate.sample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall AUC = 0.5588822503599625\n",
      "Bias score contribution : 0.3481265522855502\n",
      "Score = 0.4878471148755408\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bnsp_auc</th>\n",
       "      <th>bpsn_auc</th>\n",
       "      <th>subgroup</th>\n",
       "      <th>subgroup_auc</th>\n",
       "      <th>subgroup_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.317027</td>\n",
       "      <td>0.539426</td>\n",
       "      <td>jewish</td>\n",
       "      <td>0.323810</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.470123</td>\n",
       "      <td>0.505038</td>\n",
       "      <td>psychiatric_or_mental_illness</td>\n",
       "      <td>0.365079</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.422495</td>\n",
       "      <td>0.568346</td>\n",
       "      <td>white</td>\n",
       "      <td>0.430749</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.420804</td>\n",
       "      <td>0.604092</td>\n",
       "      <td>black</td>\n",
       "      <td>0.470690</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.569409</td>\n",
       "      <td>0.507599</td>\n",
       "      <td>male</td>\n",
       "      <td>0.520016</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.576485</td>\n",
       "      <td>0.537766</td>\n",
       "      <td>female</td>\n",
       "      <td>0.553229</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.623800</td>\n",
       "      <td>0.488001</td>\n",
       "      <td>christian</td>\n",
       "      <td>0.556935</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.603288</td>\n",
       "      <td>0.517964</td>\n",
       "      <td>muslim</td>\n",
       "      <td>0.559667</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.526310</td>\n",
       "      <td>0.606838</td>\n",
       "      <td>homosexual_gay_or_lesbian</td>\n",
       "      <td>0.565116</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bnsp_auc  bpsn_auc                       subgroup  subgroup_auc  \\\n",
       "4  0.317027  0.539426                         jewish      0.323810   \n",
       "8  0.470123  0.505038  psychiatric_or_mental_illness      0.365079   \n",
       "7  0.422495  0.568346                          white      0.430749   \n",
       "6  0.420804  0.604092                          black      0.470690   \n",
       "0  0.569409  0.507599                           male      0.520016   \n",
       "1  0.576485  0.537766                         female      0.553229   \n",
       "3  0.623800  0.488001                      christian      0.556935   \n",
       "5  0.603288  0.517964                         muslim      0.559667   \n",
       "2  0.526310  0.606838      homosexual_gay_or_lesbian      0.565116   \n",
       "\n",
       "   subgroup_size  \n",
       "4             41  \n",
       "8             24  \n",
       "7            153  \n",
       "6             78  \n",
       "0            235  \n",
       "1            299  \n",
       "3            216  \n",
       "5            117  \n",
       "2             53  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import p9_util_metrics\n",
    "\n",
    "MODEL_NAME = 'my_model'\n",
    "df_validate[MODEL_NAME] = model.predict(pad_text(df_validate[TEXT_COLUMN], tokenizer))[:, 1]\n",
    "\n",
    "import p9_util_benchmark\n",
    "df_bias_metrics = p9_util_metrics.compute_bias_metrics_for_model(df_validate, identity_columns, MODEL_NAME, TOXICITY_COLUMN)\n",
    "overall_auc = p9_util_metrics.calculate_overall_auc(df_validate, MODEL_NAME, p9_util_metrics.TOXICITY_COLUMN)\n",
    "print(\"Overall AUC = {}\".format(overall_auc))\n",
    "\n",
    "score = p9_util_metrics.get_final_metric(df_bias_metrics, overall_auc)\n",
    "print(\"Score = {}\".format(score))\n",
    "print(\"\")\n",
    "df_bias_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall AUC = 0.929906737694202\n",
      "Bias score contribution : 0.6557258772464325\n",
      "Score = 0.888202561669983\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bnsp_auc</th>\n",
       "      <th>bpsn_auc</th>\n",
       "      <th>subgroup</th>\n",
       "      <th>subgroup_auc</th>\n",
       "      <th>subgroup_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.947862</td>\n",
       "      <td>0.805555</td>\n",
       "      <td>muslim</td>\n",
       "      <td>0.818181</td>\n",
       "      <td>4261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.958519</td>\n",
       "      <td>0.785189</td>\n",
       "      <td>white</td>\n",
       "      <td>0.821673</td>\n",
       "      <td>5015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.959149</td>\n",
       "      <td>0.779959</td>\n",
       "      <td>black</td>\n",
       "      <td>0.821964</td>\n",
       "      <td>2958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.955701</td>\n",
       "      <td>0.793160</td>\n",
       "      <td>homosexual_gay_or_lesbian</td>\n",
       "      <td>0.826999</td>\n",
       "      <td>2209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.934687</td>\n",
       "      <td>0.862453</td>\n",
       "      <td>jewish</td>\n",
       "      <td>0.854121</td>\n",
       "      <td>1563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.946230</td>\n",
       "      <td>0.845690</td>\n",
       "      <td>psychiatric_or_mental_illness</td>\n",
       "      <td>0.867229</td>\n",
       "      <td>964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.931124</td>\n",
       "      <td>0.885238</td>\n",
       "      <td>female</td>\n",
       "      <td>0.880461</td>\n",
       "      <td>10789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.945799</td>\n",
       "      <td>0.870465</td>\n",
       "      <td>male</td>\n",
       "      <td>0.887908</td>\n",
       "      <td>8823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.911606</td>\n",
       "      <td>0.916216</td>\n",
       "      <td>christian</td>\n",
       "      <td>0.892852</td>\n",
       "      <td>8246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bnsp_auc  bpsn_auc                       subgroup  subgroup_auc  \\\n",
       "5  0.947862  0.805555                         muslim      0.818181   \n",
       "7  0.958519  0.785189                          white      0.821673   \n",
       "6  0.959149  0.779959                          black      0.821964   \n",
       "2  0.955701  0.793160      homosexual_gay_or_lesbian      0.826999   \n",
       "4  0.934687  0.862453                         jewish      0.854121   \n",
       "8  0.946230  0.845690  psychiatric_or_mental_illness      0.867229   \n",
       "1  0.931124  0.885238                         female      0.880461   \n",
       "0  0.945799  0.870465                           male      0.887908   \n",
       "3  0.911606  0.916216                      christian      0.892852   \n",
       "\n",
       "   subgroup_size  \n",
       "5           4261  \n",
       "7           5015  \n",
       "6           2958  \n",
       "2           2209  \n",
       "4           1563  \n",
       "8            964  \n",
       "1          10789  \n",
       "0           8823  \n",
       "3           8246  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME = 'my_model'\n",
    "df_validate[MODEL_NAME] = model.predict(pad_text(df_validate[TEXT_COLUMN], tokenizer))[:, 1]\n",
    "\n",
    "import p9_util_benchmark\n",
    "df_bias_metrics = p9_util_benchmark.compute_bias_metrics_for_model(df_validate, identity_columns, MODEL_NAME, TOXICITY_COLUMN)\n",
    "overall_auc = p9_util_benchmark.calculate_overall_auc(df_validate, MODEL_NAME)\n",
    "print(\"Overall AUC = {}\".format(overall_auc))\n",
    "\n",
    "score = p9_util_benchmark.get_final_metric(df_bias_metrics, overall_auc)\n",
    "print(\"Score = {}\".format(score))\n",
    "print(\"\")\n",
    "df_bias_metrics\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "training model\n",
    "Train on 80000 samples, validate on 20000 samples\n",
    "Epoch 1/11\n",
    "80000/80000 [==============================] - 175s 2ms/step - loss: 0.2593 - acc: 0.9206 - val_loss: 0.2097 - val_acc: 0.9260\n",
    "Epoch 2/11\n",
    "80000/80000 [==============================] - 236s 3ms/step - loss: 0.1980 - acc: 0.9293 - val_loss: 0.1832 - val_acc: 0.9335\n",
    "Epoch 3/11\n",
    "80000/80000 [==============================] - 184s 2ms/step - loss: 0.1772 - acc: 0.9361 - val_loss: 0.1788 - val_acc: 0.9354\n",
    "Epoch 4/11\n",
    "80000/80000 [==============================] - 159s 2ms/step - loss: 0.1637 - acc: 0.9409 - val_loss: 0.1727 - val_acc: 0.9397\n",
    "Epoch 5/11\n",
    "80000/80000 [==============================] - 145s 2ms/step - loss: 0.1537 - acc: 0.9433 - val_loss: 0.1700 - val_acc: 0.9381\n",
    "Epoch 6/11\n",
    "80000/80000 [==============================] - 146s 2ms/step - loss: 0.1453 - acc: 0.9469 - val_loss: 0.1679 - val_acc: 0.9416\n",
    "Epoch 7/11\n",
    "80000/80000 [==============================] - 158s 2ms/step - loss: 0.1360 - acc: 0.9499 - val_loss: 0.1780 - val_acc: 0.9315\n",
    "Epoch 8/11\n",
    "80000/80000 [==============================] - 156s 2ms/step - loss: 0.1268 - acc: 0.9530 - val_loss: 0.1674 - val_acc: 0.9415\n",
    "Epoch 9/11\n",
    "80000/80000 [==============================] - 147s 2ms/step - loss: 0.1185 - acc: 0.9562 - val_loss: 0.1798 - val_acc: 0.9430\n",
    "Epoch 10/11\n",
    "80000/80000 [==============================] - 147s 2ms/step - loss: 0.1082 - acc: 0.9598 - val_loss: 0.1802 - val_acc: 0.9334\n",
    "Epoch 11/11\n",
    "80000/80000 [==============================] - 145s 2ms/step - loss: 0.0990 - acc: 0.9636 - val_loss: 0.1880 - val_acc: 0.9320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import p5_util\n",
    "import p9_util_benchmark\n",
    "\n",
    "#dict_param_benchmark = p9_util_benchmark.dict_param_benchmark.copy()\n",
    "dict_param_benchmark\n",
    "#------------------------------------------------------------\n",
    "# Save history\n",
    "#------------------------------------------------------------\n",
    "filename_history = p9_util_benchmark.build_filename_history(dict_param_benchmark=dict_param_benchmark)\n",
    "p5_util.object_dump(history, filename_history, is_verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall AUC = 0.9235434268035685\n",
      "Bias score contribution : 0.6504264097286355\n",
      "Score = 0.8813122664295276\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bnsp_auc</th>\n",
       "      <th>bpsn_auc</th>\n",
       "      <th>subgroup</th>\n",
       "      <th>subgroup_auc</th>\n",
       "      <th>subgroup_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.955746</td>\n",
       "      <td>0.741333</td>\n",
       "      <td>black</td>\n",
       "      <td>0.774689</td>\n",
       "      <td>877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.946683</td>\n",
       "      <td>0.774918</td>\n",
       "      <td>homosexual_gay_or_lesbian</td>\n",
       "      <td>0.796854</td>\n",
       "      <td>634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.958981</td>\n",
       "      <td>0.762359</td>\n",
       "      <td>white</td>\n",
       "      <td>0.811306</td>\n",
       "      <td>1377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.948299</td>\n",
       "      <td>0.803654</td>\n",
       "      <td>muslim</td>\n",
       "      <td>0.820926</td>\n",
       "      <td>1190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.943460</td>\n",
       "      <td>0.849810</td>\n",
       "      <td>jewish</td>\n",
       "      <td>0.864738</td>\n",
       "      <td>440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.939573</td>\n",
       "      <td>0.853694</td>\n",
       "      <td>male</td>\n",
       "      <td>0.868016</td>\n",
       "      <td>2399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.945457</td>\n",
       "      <td>0.863649</td>\n",
       "      <td>female</td>\n",
       "      <td>0.888232</td>\n",
       "      <td>2992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.932038</td>\n",
       "      <td>0.903479</td>\n",
       "      <td>christian</td>\n",
       "      <td>0.911376</td>\n",
       "      <td>2212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.968030</td>\n",
       "      <td>0.835439</td>\n",
       "      <td>psychiatric_or_mental_illness</td>\n",
       "      <td>0.913961</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bnsp_auc  bpsn_auc                       subgroup  subgroup_auc  \\\n",
       "6  0.955746  0.741333                          black      0.774689   \n",
       "2  0.946683  0.774918      homosexual_gay_or_lesbian      0.796854   \n",
       "7  0.958981  0.762359                          white      0.811306   \n",
       "5  0.948299  0.803654                         muslim      0.820926   \n",
       "4  0.943460  0.849810                         jewish      0.864738   \n",
       "0  0.939573  0.853694                           male      0.868016   \n",
       "1  0.945457  0.863649                         female      0.888232   \n",
       "3  0.932038  0.903479                      christian      0.911376   \n",
       "8  0.968030  0.835439  psychiatric_or_mental_illness      0.913961   \n",
       "\n",
       "   subgroup_size  \n",
       "6            877  \n",
       "2            634  \n",
       "7           1377  \n",
       "5           1190  \n",
       "4            440  \n",
       "0           2399  \n",
       "1           2992  \n",
       "3           2212  \n",
       "8            254  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME = 'my_model'\n",
    "df_validate[MODEL_NAME] = model.predict(pad_text(df_validate[TEXT_COLUMN], tokenizer))[:, 1]\n",
    "\n",
    "import p9_util_benchmark\n",
    "df_bias_metrics = p9_util_benchmark.compute_bias_metrics_for_model(df_validate, identity_columns, MODEL_NAME, TOXICITY_COLUMN)\n",
    "overall_auc = p9_util_benchmark.calculate_overall_auc(df_validate, MODEL_NAME)\n",
    "print(\"Overall AUC = {}\".format(overall_auc))\n",
    "\n",
    "score = p9_util_benchmark.get_final_metric(df_bias_metrics, overall_auc)\n",
    "print(\"Score = {}\".format(score))\n",
    "print(\"\")\n",
    "df_bias_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall AUC = 0.8773481156459169\n",
      "Bias score contribution : 0.615308740767306\n",
      "Score = 0.8346457696787852\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bnsp_auc</th>\n",
       "      <th>bpsn_auc</th>\n",
       "      <th>subgroup</th>\n",
       "      <th>subgroup_auc</th>\n",
       "      <th>subgroup_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.860107</td>\n",
       "      <td>0.754596</td>\n",
       "      <td>homosexual_gay_or_lesbian</td>\n",
       "      <td>0.732222</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.818222</td>\n",
       "      <td>0.802380</td>\n",
       "      <td>jewish</td>\n",
       "      <td>0.751323</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.912800</td>\n",
       "      <td>0.741271</td>\n",
       "      <td>black</td>\n",
       "      <td>0.787715</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.778932</td>\n",
       "      <td>0.891993</td>\n",
       "      <td>psychiatric_or_mental_illness</td>\n",
       "      <td>0.788235</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.924140</td>\n",
       "      <td>0.766183</td>\n",
       "      <td>muslim</td>\n",
       "      <td>0.795966</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.865721</td>\n",
       "      <td>0.839276</td>\n",
       "      <td>female</td>\n",
       "      <td>0.821829</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.899045</td>\n",
       "      <td>0.812364</td>\n",
       "      <td>male</td>\n",
       "      <td>0.826001</td>\n",
       "      <td>262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.933312</td>\n",
       "      <td>0.746423</td>\n",
       "      <td>white</td>\n",
       "      <td>0.837827</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.934860</td>\n",
       "      <td>0.858851</td>\n",
       "      <td>christian</td>\n",
       "      <td>0.924326</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bnsp_auc  bpsn_auc                       subgroup  subgroup_auc  \\\n",
       "2  0.860107  0.754596      homosexual_gay_or_lesbian      0.732222   \n",
       "4  0.818222  0.802380                         jewish      0.751323   \n",
       "6  0.912800  0.741271                          black      0.787715   \n",
       "8  0.778932  0.891993  psychiatric_or_mental_illness      0.788235   \n",
       "5  0.924140  0.766183                         muslim      0.795966   \n",
       "1  0.865721  0.839276                         female      0.821829   \n",
       "0  0.899045  0.812364                           male      0.826001   \n",
       "7  0.933312  0.746423                          white      0.837827   \n",
       "3  0.934860  0.858851                      christian      0.924326   \n",
       "\n",
       "   subgroup_size  \n",
       "2             61  \n",
       "4             34  \n",
       "6             92  \n",
       "8             22  \n",
       "5            108  \n",
       "1            309  \n",
       "0            262  \n",
       "7            149  \n",
       "3            220  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME = 'my_model'\n",
    "df_validate[MODEL_NAME] = model.predict(pad_text(df_validate[TEXT_COLUMN], tokenizer))[:, 1]\n",
    "\n",
    "import p9_util_benchmark\n",
    "df_bias_metrics = p9_util_benchmark.compute_bias_metrics_for_model(df_validate, identity_columns, MODEL_NAME, TOXICITY_COLUMN)\n",
    "overall_auc = p9_util_benchmark.calculate_overall_auc(df_validate, MODEL_NAME)\n",
    "print(\"Overall AUC = {}\".format(overall_auc))\n",
    "\n",
    "score = p9_util_benchmark.get_final_metric(df_bias_metrics, overall_auc)\n",
    "print(\"Score = {}\".format(score))\n",
    "print(\"\")\n",
    "df_bias_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall AUC = 0.8773481156459169\n",
      "Bias score contribution : 0.615308740767306\n",
      "Score = 0.8346457696787852\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Overall AUC = 0.8773481156459169\n",
    "Bias score contribution : 0.615308740767306\n",
    "Score = 0.8346457696787852\n",
    "\n",
    "training model\n",
    "Train on 40000 samples, validate on 10000 samples\n",
    "Epoch 1/20\n",
    "40000/40000 [==============================] - 108s 3ms/step - loss: 0.2985 - acc: 0.9170 - val_loss: 0.2753 - val_acc: 0.9159\n",
    "Epoch 2/20\n",
    "40000/40000 [==============================] - 197s 5ms/step - loss: 0.2499 - acc: 0.9170 - val_loss: 0.2596 - val_acc: 0.9159\n",
    "Epoch 3/20\n",
    "40000/40000 [==============================] - 187s 5ms/step - loss: 0.2134 - acc: 0.9199 - val_loss: 0.2202 - val_acc: 0.9231\n",
    "Epoch 4/20\n",
    "40000/40000 [==============================] - 148s 4ms/step - loss: 0.1937 - acc: 0.9280 - val_loss: 0.2194 - val_acc: 0.9257\n",
    "Epoch 5/20\n",
    "40000/40000 [==============================] - 130s 3ms/step - loss: 0.1791 - acc: 0.9315 - val_loss: 0.1977 - val_acc: 0.9292\n",
    "Epoch 6/20\n",
    "40000/40000 [==============================] - 117s 3ms/step - loss: 0.1670 - acc: 0.9355 - val_loss: 0.1927 - val_acc: 0.9305\n",
    "Epoch 7/20\n",
    "40000/40000 [==============================] - 107s 3ms/step - loss: 0.1564 - acc: 0.9407 - val_loss: 0.2011 - val_acc: 0.9317\n",
    "Epoch 8/20\n",
    "40000/40000 [==============================] - 101s 3ms/step - loss: 0.1452 - acc: 0.9443 - val_loss: 0.2359 - val_acc: 0.9320\n",
    "Epoch 9/20\n",
    "40000/40000 [==============================] - 100s 3ms/step - loss: 0.1340 - acc: 0.9493 - val_loss: 0.1960 - val_acc: 0.9303\n",
    "Epoch 10/20\n",
    "40000/40000 [==============================] - 169s 4ms/step - loss: 0.1212 - acc: 0.9539 - val_loss: 0.2183 - val_acc: 0.9342\n",
    "Epoch 11/20\n",
    "40000/40000 [==============================] - 170s 4ms/step - loss: 0.1101 - acc: 0.9575 - val_loss: 0.2137 - val_acc: 0.9188\n",
    "Epoch 12/20\n",
    "40000/40000 [==============================] - 172s 4ms/step - loss: 0.0969 - acc: 0.9636 - val_loss: 0.2221 - val_acc: 0.9314\n",
    "Epoch 13/20\n",
    "40000/40000 [==============================] - 173s 4ms/step - loss: 0.0851 - acc: 0.9689 - val_loss: 0.2391 - val_acc: 0.9288\n",
    "Epoch 14/20\n",
    "40000/40000 [==============================] - 173s 4ms/step - loss: 0.0770 - acc: 0.9716 - val_loss: 0.2455 - val_acc: 0.9129\n",
    "Epoch 15/20\n",
    "40000/40000 [==============================] - 172s 4ms/step - loss: 0.0646 - acc: 0.9780 - val_loss: 0.2531 - val_acc: 0.9255\n",
    "Epoch 16/20\n",
    "40000/40000 [==============================] - 174s 4ms/step - loss: 0.0546 - acc: 0.9824 - val_loss: 0.2864 - val_acc: 0.9264\n",
    "Epoch 17/20\n",
    "40000/40000 [==============================] - 175s 4ms/step - loss: 0.0465 - acc: 0.9854 - val_loss: 0.3325 - val_acc: 0.9328\n",
    "Epoch 18/20\n",
    "40000/40000 [==============================] - 177s 4ms/step - loss: 0.0442 - acc: 0.9869 - val_loss: 0.3516 - val_acc: 0.9333\n",
    "Epoch 19/20\n",
    "40000/40000 [==============================] - 174s 4ms/step - loss: 0.0362 - acc: 0.9893 - val_loss: 0.3407 - val_acc: 0.9239\n",
    "Epoch 20/20\n",
    "40000/40000 [==============================] - 176s 4ms/step - loss: 0.0331 - acc: 0.9921 - val_loss: 0.3695 - val_acc: 0.9290"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions over validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bnsp_auc</th>\n",
       "      <th>bpsn_auc</th>\n",
       "      <th>subgroup</th>\n",
       "      <th>subgroup_auc</th>\n",
       "      <th>subgroup_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.731569</td>\n",
       "      <td>0.821137</td>\n",
       "      <td>psychiatric_or_mental_illness</td>\n",
       "      <td>0.717647</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.855819</td>\n",
       "      <td>0.757932</td>\n",
       "      <td>homosexual_gay_or_lesbian</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.866616</td>\n",
       "      <td>0.740886</td>\n",
       "      <td>black</td>\n",
       "      <td>0.739558</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.888712</td>\n",
       "      <td>0.780131</td>\n",
       "      <td>jewish</td>\n",
       "      <td>0.751323</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.840319</td>\n",
       "      <td>0.812571</td>\n",
       "      <td>male</td>\n",
       "      <td>0.771372</td>\n",
       "      <td>262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.834556</td>\n",
       "      <td>0.829489</td>\n",
       "      <td>female</td>\n",
       "      <td>0.780331</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.921840</td>\n",
       "      <td>0.731057</td>\n",
       "      <td>white</td>\n",
       "      <td>0.807296</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.919802</td>\n",
       "      <td>0.774173</td>\n",
       "      <td>muslim</td>\n",
       "      <td>0.821295</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.904666</td>\n",
       "      <td>0.867893</td>\n",
       "      <td>christian</td>\n",
       "      <td>0.910186</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bnsp_auc  bpsn_auc                       subgroup  subgroup_auc  \\\n",
       "8  0.731569  0.821137  psychiatric_or_mental_illness      0.717647   \n",
       "2  0.855819  0.757932      homosexual_gay_or_lesbian      0.733333   \n",
       "6  0.866616  0.740886                          black      0.739558   \n",
       "4  0.888712  0.780131                         jewish      0.751323   \n",
       "0  0.840319  0.812571                           male      0.771372   \n",
       "1  0.834556  0.829489                         female      0.780331   \n",
       "7  0.921840  0.731057                          white      0.807296   \n",
       "5  0.919802  0.774173                         muslim      0.821295   \n",
       "3  0.904666  0.867893                      christian      0.910186   \n",
       "\n",
       "   subgroup_size  \n",
       "8             22  \n",
       "2             61  \n",
       "6             92  \n",
       "4             34  \n",
       "0            262  \n",
       "1            309  \n",
       "7            149  \n",
       "5            108  \n",
       "3            220  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME = 'my_model'\n",
    "df_validate[MODEL_NAME] = model.predict(pad_text(df_validate[TEXT_COLUMN], tokenizer))[:, 1]\n",
    "\n",
    "import p9_util_benchmark\n",
    "df_bias_metrics = p9_util_benchmark.compute_bias_metrics_for_model(df_validate, identity_columns, MODEL_NAME, TOXICITY_COLUMN)\n",
    "df_bias_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8674375892460832\n",
      "Bias score contribution : 0.6012027589900717\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8180621563015925"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_auc = p9_util_benchmark.calculate_overall_auc(df_validate, MODEL_NAME)\n",
    "print(overall_auc)\n",
    "\n",
    "p9_util_benchmark.get_final_metric(df_bias_metrics, overall_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bnsp_auc</th>\n",
       "      <th>bpsn_auc</th>\n",
       "      <th>subgroup</th>\n",
       "      <th>subgroup_auc</th>\n",
       "      <th>subgroup_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.919121</td>\n",
       "      <td>0.729760</td>\n",
       "      <td>black</td>\n",
       "      <td>0.788206</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.878579</td>\n",
       "      <td>0.804194</td>\n",
       "      <td>homosexual_gay_or_lesbian</td>\n",
       "      <td>0.788889</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.935725</td>\n",
       "      <td>0.732650</td>\n",
       "      <td>muslim</td>\n",
       "      <td>0.796904</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.948050</td>\n",
       "      <td>0.701632</td>\n",
       "      <td>white</td>\n",
       "      <td>0.804718</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.873481</td>\n",
       "      <td>0.833897</td>\n",
       "      <td>female</td>\n",
       "      <td>0.808754</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.899798</td>\n",
       "      <td>0.807535</td>\n",
       "      <td>male</td>\n",
       "      <td>0.826001</td>\n",
       "      <td>262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.863115</td>\n",
       "      <td>0.909583</td>\n",
       "      <td>psychiatric_or_mental_illness</td>\n",
       "      <td>0.870588</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.965130</td>\n",
       "      <td>0.730704</td>\n",
       "      <td>jewish</td>\n",
       "      <td>0.873016</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.938003</td>\n",
       "      <td>0.871664</td>\n",
       "      <td>christian</td>\n",
       "      <td>0.933229</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bnsp_auc  bpsn_auc                       subgroup  subgroup_auc  \\\n",
       "6  0.919121  0.729760                          black      0.788206   \n",
       "2  0.878579  0.804194      homosexual_gay_or_lesbian      0.788889   \n",
       "5  0.935725  0.732650                         muslim      0.796904   \n",
       "7  0.948050  0.701632                          white      0.804718   \n",
       "1  0.873481  0.833897                         female      0.808754   \n",
       "0  0.899798  0.807535                           male      0.826001   \n",
       "8  0.863115  0.909583  psychiatric_or_mental_illness      0.870588   \n",
       "4  0.965130  0.730704                         jewish      0.873016   \n",
       "3  0.938003  0.871664                      christian      0.933229   \n",
       "\n",
       "   subgroup_size  \n",
       "6             92  \n",
       "2             61  \n",
       "5            108  \n",
       "7            149  \n",
       "1            309  \n",
       "0            262  \n",
       "8             22  \n",
       "4             34  \n",
       "3            220  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME = 'my_model'\n",
    "df_validate[MODEL_NAME] = model.predict(pad_text(df_validate[TEXT_COLUMN], tokenizer))[:, 1]\n",
    "\n",
    "import p9_util_benchmark\n",
    "df_bias_metrics = p9_util_benchmark.compute_bias_metrics_for_model(df_validate, identity_columns, MODEL_NAME, TOXICITY_COLUMN)\n",
    "df_bias_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8828159251298147\n",
      "Bias score contribution : 0.6274428311249021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8481468124073557"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_auc = p9_util_benchmark.calculate_overall_auc(df_validate, MODEL_NAME)\n",
    "print(overall_auc)\n",
    "\n",
    "p9_util_benchmark.get_final_metric(df_bias_metrics, overall_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bnsp_auc</th>\n",
       "      <th>bpsn_auc</th>\n",
       "      <th>subgroup</th>\n",
       "      <th>subgroup_auc</th>\n",
       "      <th>subgroup_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.703854</td>\n",
       "      <td>0.842689</td>\n",
       "      <td>female</td>\n",
       "      <td>0.716502</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.781857</td>\n",
       "      <td>0.782033</td>\n",
       "      <td>homosexual_gay_or_lesbian</td>\n",
       "      <td>0.732778</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.816646</td>\n",
       "      <td>0.756270</td>\n",
       "      <td>muslim</td>\n",
       "      <td>0.736398</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.824397</td>\n",
       "      <td>0.753858</td>\n",
       "      <td>white</td>\n",
       "      <td>0.743259</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.811353</td>\n",
       "      <td>0.790321</td>\n",
       "      <td>black</td>\n",
       "      <td>0.761179</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.781616</td>\n",
       "      <td>0.794209</td>\n",
       "      <td>jewish</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.772935</td>\n",
       "      <td>0.863786</td>\n",
       "      <td>christian</td>\n",
       "      <td>0.808850</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.831307</td>\n",
       "      <td>0.811742</td>\n",
       "      <td>male</td>\n",
       "      <td>0.810467</td>\n",
       "      <td>262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.796806</td>\n",
       "      <td>0.859626</td>\n",
       "      <td>psychiatric_or_mental_illness</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bnsp_auc  bpsn_auc                       subgroup  subgroup_auc  \\\n",
       "1  0.703854  0.842689                         female      0.716502   \n",
       "2  0.781857  0.782033      homosexual_gay_or_lesbian      0.732778   \n",
       "5  0.816646  0.756270                         muslim      0.736398   \n",
       "7  0.824397  0.753858                          white      0.743259   \n",
       "6  0.811353  0.790321                          black      0.761179   \n",
       "4  0.781616  0.794209                         jewish      0.761905   \n",
       "3  0.772935  0.863786                      christian      0.808850   \n",
       "0  0.831307  0.811742                           male      0.810467   \n",
       "8  0.796806  0.859626  psychiatric_or_mental_illness      0.823529   \n",
       "\n",
       "   subgroup_size  \n",
       "1            309  \n",
       "2             61  \n",
       "5            108  \n",
       "7            149  \n",
       "6             92  \n",
       "4             34  \n",
       "3            220  \n",
       "0            262  \n",
       "8             22  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME = 'my_model'\n",
    "df_validate[MODEL_NAME] = model.predict(pad_text(df_validate[TEXT_COLUMN], tokenizer))[:, 1]\n",
    "\n",
    "import p9_util_benchmark\n",
    "df_bias_metrics = p9_util_benchmark.compute_bias_metrics_for_model(df_validate, identity_columns, MODEL_NAME, TOXICITY_COLUMN)\n",
    "df_bias_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.82918226667752\n",
      "Bias score contribution : 0.586736648403426\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.794032215072806"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_auc = p9_util_benchmark.calculate_overall_auc(df_validate, MODEL_NAME)\n",
    "print(overall_auc)\n",
    "\n",
    "p9_util_benchmark.get_final_metric(df_bias_metrics, overall_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bnsp_auc</th>\n",
       "      <th>bpsn_auc</th>\n",
       "      <th>subgroup</th>\n",
       "      <th>subgroup_auc</th>\n",
       "      <th>subgroup_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.902744</td>\n",
       "      <td>0.756994</td>\n",
       "      <td>jewish</td>\n",
       "      <td>0.735450</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.917835</td>\n",
       "      <td>0.714405</td>\n",
       "      <td>black</td>\n",
       "      <td>0.736118</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.899222</td>\n",
       "      <td>0.769472</td>\n",
       "      <td>homosexual_gay_or_lesbian</td>\n",
       "      <td>0.771111</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.929789</td>\n",
       "      <td>0.771300</td>\n",
       "      <td>muslim</td>\n",
       "      <td>0.813790</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.944449</td>\n",
       "      <td>0.743588</td>\n",
       "      <td>white</td>\n",
       "      <td>0.819389</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.897253</td>\n",
       "      <td>0.821464</td>\n",
       "      <td>male</td>\n",
       "      <td>0.828190</td>\n",
       "      <td>262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.882863</td>\n",
       "      <td>0.845516</td>\n",
       "      <td>female</td>\n",
       "      <td>0.836609</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.891730</td>\n",
       "      <td>0.873276</td>\n",
       "      <td>psychiatric_or_mental_illness</td>\n",
       "      <td>0.870588</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.915712</td>\n",
       "      <td>0.872995</td>\n",
       "      <td>christian</td>\n",
       "      <td>0.907567</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bnsp_auc  bpsn_auc                       subgroup  subgroup_auc  \\\n",
       "4  0.902744  0.756994                         jewish      0.735450   \n",
       "6  0.917835  0.714405                          black      0.736118   \n",
       "2  0.899222  0.769472      homosexual_gay_or_lesbian      0.771111   \n",
       "5  0.929789  0.771300                         muslim      0.813790   \n",
       "7  0.944449  0.743588                          white      0.819389   \n",
       "0  0.897253  0.821464                           male      0.828190   \n",
       "1  0.882863  0.845516                         female      0.836609   \n",
       "8  0.891730  0.873276  psychiatric_or_mental_illness      0.870588   \n",
       "3  0.915712  0.872995                      christian      0.907567   \n",
       "\n",
       "   subgroup_size  \n",
       "4             34  \n",
       "6             92  \n",
       "2             61  \n",
       "5            108  \n",
       "7            149  \n",
       "0            262  \n",
       "1            309  \n",
       "8             22  \n",
       "3            220  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME = 'my_model'\n",
    "df_validate[MODEL_NAME] = model.predict(pad_text(df_validate[TEXT_COLUMN], tokenizer))[:, 1]\n",
    "\n",
    "import p9_util_benchmark\n",
    "df_bias_metrics = p9_util_benchmark.compute_bias_metrics_for_model(df_validate, identity_columns, MODEL_NAME, TOXICITY_COLUMN)\n",
    "df_bias_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8866337977537542\n",
      "Bias score contribution : 0.6239334298311822\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8455918792696206"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_auc = p9_util_benchmark.calculate_overall_auc(df_validate, MODEL_NAME)\n",
    "print(overall_auc)\n",
    "\n",
    "p9_util_benchmark.get_final_metric(df_bias_metrics, overall_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8813846123686974\n",
      "Bias score contribution : 0.6311989177686654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8515450708608397"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_auc = p9_util_benchmark.calculate_overall_auc(df_validate, MODEL_NAME)\n",
    "print(overall_auc)\n",
    "\n",
    "p9_util_benchmark.get_final_metric(df_bias_metrics, overall_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "training model\n",
    "Train on 1443899 samples, validate on 360975 samples\n",
    "Epoch 1/10\n",
    "1443899/1443899 [==============================] - 2508s 2ms/step - loss: 0.4531 - acc: 0.7964 - val_loss: 0.4414 - val_acc: 0.8070\n",
    "Epoch 2/10\n",
    "1443899/1443899 [==============================] - 2521s 2ms/step - loss: 0.4301 - acc: 0.8100 - val_loss: 0.4443 - val_acc: 0.8023\n",
    "Epoch 3/10\n",
    "1443899/1443899 [==============================] - 2518s 2ms/step - loss: 0.4248 - acc: 0.8130 - val_loss: 0.4558 - val_acc: 0.8053\n",
    "Epoch 4/10\n",
    "1443899/1443899 [==============================] - 2525s 2ms/step - loss: 0.4229 - acc: 0.8149 - val_loss: 0.4497 - val_acc: 0.8088\n",
    "Epoch 5/10\n",
    "1443899/1443899 [==============================] - 2517s 2ms/step - loss: 0.4198 - acc: 0.8165 - val_loss: 0.4374 - val_acc: 0.8106\n",
    "Epoch 6/10\n",
    "1443899/1443899 [==============================] - 2513s 2ms/step - loss: 0.4158 - acc: 0.8186 - val_loss: 0.4427 - val_acc: 0.8098\n",
    "Epoch 7/10\n",
    "1443899/1443899 [==============================] - 2513s 2ms/step - loss: 0.4139 - acc: 0.8199 - val_loss: 0.5491 - val_acc: 0.7687\n",
    "Epoch 8/10\n",
    "1443899/1443899 [==============================] - 2533s 2ms/step - loss: 0.4117 - acc: 0.8209 - val_loss: 0.4880 - val_acc: 0.7946\n",
    "Epoch 9/10\n",
    "1443899/1443899 [==============================] - 2818s 2ms/step - loss: 1.6096 - acc: 0.7931 - val_loss: 3.6802 - val_acc: 0.7696\n",
    "Epoch 10/10\n",
    "1443899/1443899 [==============================] - 3010s 2ms/step - loss: 3.6596 - acc: 0.7722 - val_loss: 3.5421 - val_acc: 0.7799"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "training model\n",
    "Train on 160000 samples, validate on 40000 samples\n",
    "Epoch 1/10\n",
    "160000/160000 [==============================] - 398s 2ms/step - loss: 0.5049 - acc: 0.7628 - val_loss: 0.4584 - val_acc: 0.7942\n",
    "Epoch 2/10\n",
    "160000/160000 [==============================] - 372s 2ms/step - loss: 0.4539 - acc: 0.7950 - val_loss: 0.4465 - val_acc: 0.8005\n",
    "Epoch 3/10\n",
    "160000/160000 [==============================] - 408s 3ms/step - loss: 0.4341 - acc: 0.8055 - val_loss: 0.4484 - val_acc: 0.8028\n",
    "Epoch 4/10\n",
    "160000/160000 [==============================] - 395s 2ms/step - loss: 0.4142 - acc: 0.8160 - val_loss: 0.4549 - val_acc: 0.8010\n",
    "Epoch 5/10\n",
    "160000/160000 [==============================] - 422s 3ms/step - loss: 0.3913 - acc: 0.8271 - val_loss: 0.4674 - val_acc: 0.7851\n",
    "Epoch 6/10\n",
    "160000/160000 [==============================] - 431s 3ms/step - loss: 0.3666 - acc: 0.8396 - val_loss: 0.4931 - val_acc: 0.7913\n",
    "Epoch 7/10\n",
    "160000/160000 [==============================] - 378s 2ms/step - loss: 0.3375 - acc: 0.8537 - val_loss: 0.5611 - val_acc: 0.7565\n",
    "Epoch 8/10\n",
    "160000/160000 [==============================] - 423s 3ms/step - loss: 0.3074 - acc: 0.8690 - val_loss: 0.6075 - val_acc: 0.7473\n",
    "Epoch 9/10\n",
    "160000/160000 [==============================] - 372s 2ms/step - loss: 0.2781 - acc: 0.8833 - val_loss: 0.5815 - val_acc: 0.7862\n",
    "Epoch 10/10\n",
    "160000/160000 [==============================] - 426s 3ms/step - loss: 0.2489 - acc: 0.8972 - val_loss: 0.6220 - val_acc: 0.7329"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "training model\n",
    "Train on 48000 samples, validate on 12000 samples\n",
    "Epoch 1/10\n",
    "48000/48000 [==============================] - 126s 3ms/step - loss: 0.5563 - acc: 0.7292 - val_loss: 0.5019 - val_acc: 0.7596\n",
    "Epoch 2/10\n",
    "48000/48000 [==============================] - 132s 3ms/step - loss: 0.4896 - acc: 0.7697 - val_loss: 0.4773 - val_acc: 0.7771\n",
    "Epoch 3/10\n",
    "48000/48000 [==============================] - 111s 2ms/step - loss: 0.4623 - acc: 0.7881 - val_loss: 0.4776 - val_acc: 0.7748\n",
    "Epoch 4/10\n",
    "48000/48000 [==============================] - 119s 2ms/step - loss: 0.4403 - acc: 0.8007 - val_loss: 0.4878 - val_acc: 0.7675\n",
    "Epoch 5/10\n",
    "48000/48000 [==============================] - 109s 2ms/step - loss: 0.4164 - acc: 0.8141 - val_loss: 0.4817 - val_acc: 0.7887\n",
    "Epoch 6/10\n",
    "48000/48000 [==============================] - 110s 2ms/step - loss: 0.3887 - acc: 0.8297 - val_loss: 0.5198 - val_acc: 0.7863\n",
    "Epoch 7/10\n",
    "48000/48000 [==============================] - 130s 3ms/step - loss: 0.3601 - acc: 0.8456 - val_loss: 0.5105 - val_acc: 0.7657\n",
    "Epoch 8/10\n",
    "48000/48000 [==============================] - 148s 3ms/step - loss: 0.3238 - acc: 0.8656 - val_loss: 0.5695 - val_acc: 0.7846\n",
    "Epoch 9/10\n",
    "48000/48000 [==============================] - 149s 3ms/step - loss: 0.2920 - acc: 0.8795 - val_loss: 0.5647 - val_acc: 0.7835\n",
    "Epoch 10/10\n",
    "48000/48000 [==============================] - 146s 3ms/step - loss: 0.2549 - acc: 0.8997 - val_loss: 0.6876 - val_acc: 0.7069"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "training model\n",
    "Train on 48000 samples, validate on 12000 samples\n",
    "Epoch 1/10\n",
    "48000/48000 [==============================] - 115s 2ms/step - loss: 0.5491 - acc: 0.7308 - val_loss: 0.4947 - val_acc: 0.7661\n",
    "Epoch 2/10\n",
    "48000/48000 [==============================] - 123s 3ms/step - loss: 0.4862 - acc: 0.7742 - val_loss: 0.4813 - val_acc: 0.7738\n",
    "Epoch 3/10\n",
    "48000/48000 [==============================] - 117s 2ms/step - loss: 0.4593 - acc: 0.7904 - val_loss: 0.4833 - val_acc: 0.7742\n",
    "Epoch 4/10\n",
    "48000/48000 [==============================] - 112s 2ms/step - loss: 0.4358 - acc: 0.8042 - val_loss: 0.4644 - val_acc: 0.7892\n",
    "Epoch 5/10\n",
    "48000/48000 [==============================] - 104s 2ms/step - loss: 0.4138 - acc: 0.8153 - val_loss: 0.4656 - val_acc: 0.7883\n",
    "Epoch 6/10\n",
    "48000/48000 [==============================] - 108s 2ms/step - loss: 0.3856 - acc: 0.8314 - val_loss: 0.5006 - val_acc: 0.7881\n",
    "Epoch 7/10\n",
    "48000/48000 [==============================] - 109s 2ms/step - loss: 0.3579 - acc: 0.8454 - val_loss: 0.5354 - val_acc: 0.7442\n",
    "Epoch 8/10\n",
    "48000/48000 [==============================] - 109s 2ms/step - loss: 0.3276 - acc: 0.8611 - val_loss: 0.5060 - val_acc: 0.7796\n",
    "Epoch 9/10\n",
    "48000/48000 [==============================] - 112s 2ms/step - loss: 0.2989 - acc: 0.8751 - val_loss: 0.5393 - val_acc: 0.7833\n",
    "Epoch 10/10\n",
    "48000/48000 [==============================] - 108s 2ms/step - loss: 0.2639 - acc: 0.8914 - val_loss: 0.5626 - val_acc: 0.7742"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "training model\n",
    "Train on 48000 samples, validate on 12000 samples\n",
    "Epoch 1/10\n",
    "48000/48000 [==============================] - 53s 1ms/step - loss: 0.5926 - acc: 0.7048 - val_loss: 0.5709 - val_acc: 0.7082\n",
    "Epoch 2/10\n",
    "48000/48000 [==============================] - 47s 982us/step - loss: 0.5525 - acc: 0.7236 - val_loss: 0.5506 - val_acc: 0.7265\n",
    "Epoch 3/10\n",
    "48000/48000 [==============================] - 45s 928us/step - loss: 0.5294 - acc: 0.7414 - val_loss: 0.5254 - val_acc: 0.7445\n",
    "Epoch 4/10\n",
    "48000/48000 [==============================] - 48s 1ms/step - loss: 0.5142 - acc: 0.7509 - val_loss: 0.5306 - val_acc: 0.7413\n",
    "Epoch 5/10\n",
    "48000/48000 [==============================] - 45s 937us/step - loss: 0.5028 - acc: 0.7590 - val_loss: 0.5086 - val_acc: 0.7570\n",
    "Epoch 6/10\n",
    "48000/48000 [==============================] - 49s 1ms/step - loss: 0.4944 - acc: 0.7662 - val_loss: 0.5240 - val_acc: 0.7465\n",
    "Epoch 7/10\n",
    "48000/48000 [==============================] - 42s 875us/step - loss: 0.4868 - acc: 0.7720 - val_loss: 0.5022 - val_acc: 0.7644\n",
    "Epoch 8/10\n",
    "48000/48000 [==============================] - 43s 895us/step - loss: 0.4797 - acc: 0.7752 - val_loss: 0.5003 - val_acc: 0.7625\n",
    "Epoch 9/10\n",
    "48000/48000 [==============================] - 44s 914us/step - loss: 0.4739 - acc: 0.7799 - val_loss: 0.4956 - val_acc: 0.7653\n",
    "Epoch 10/10\n",
    "48000/48000 [==============================] - 51s 1ms/step - loss: 0.4676 - acc: 0.7826 - val_loss: 0.4944 - val_acc: 0.7667"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import p5_util\n",
    "p5_util.object_dump(history,'./data/benchmark/history_20Epoch_50000.dill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p5_util.object_load : fileName= ./data/benchmark/df_sample_benchmark_valid_360975.dill\n"
     ]
    }
   ],
   "source": [
    "import p5_util\n",
    "df_validate = p5_util.object_load('./data/benchmark/df_sample_benchmark_valid_360975.dill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "360975"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions over validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bnsp_auc</th>\n",
       "      <th>bpsn_auc</th>\n",
       "      <th>subgroup</th>\n",
       "      <th>subgroup_auc</th>\n",
       "      <th>subgroup_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.423482</td>\n",
       "      <td>0.527633</td>\n",
       "      <td>male</td>\n",
       "      <td>0.479227</td>\n",
       "      <td>16117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.379671</td>\n",
       "      <td>0.578172</td>\n",
       "      <td>muslim</td>\n",
       "      <td>0.485176</td>\n",
       "      <td>5200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.413221</td>\n",
       "      <td>0.545691</td>\n",
       "      <td>female</td>\n",
       "      <td>0.486553</td>\n",
       "      <td>14774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.420225</td>\n",
       "      <td>0.537800</td>\n",
       "      <td>homosexual_gay_or_lesbian</td>\n",
       "      <td>0.488713</td>\n",
       "      <td>3034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.395996</td>\n",
       "      <td>0.564799</td>\n",
       "      <td>christian</td>\n",
       "      <td>0.488767</td>\n",
       "      <td>12325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.412021</td>\n",
       "      <td>0.552818</td>\n",
       "      <td>white</td>\n",
       "      <td>0.493640</td>\n",
       "      <td>6094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.386923</td>\n",
       "      <td>0.587823</td>\n",
       "      <td>jewish</td>\n",
       "      <td>0.501126</td>\n",
       "      <td>2079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.415539</td>\n",
       "      <td>0.561902</td>\n",
       "      <td>black</td>\n",
       "      <td>0.506197</td>\n",
       "      <td>3961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.441750</td>\n",
       "      <td>0.553171</td>\n",
       "      <td>psychiatric_or_mental_illness</td>\n",
       "      <td>0.523564</td>\n",
       "      <td>2057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bnsp_auc  bpsn_auc                       subgroup  subgroup_auc  \\\n",
       "0  0.423482  0.527633                           male      0.479227   \n",
       "5  0.379671  0.578172                         muslim      0.485176   \n",
       "1  0.413221  0.545691                         female      0.486553   \n",
       "2  0.420225  0.537800      homosexual_gay_or_lesbian      0.488713   \n",
       "3  0.395996  0.564799                      christian      0.488767   \n",
       "7  0.412021  0.552818                          white      0.493640   \n",
       "4  0.386923  0.587823                         jewish      0.501126   \n",
       "6  0.415539  0.561902                          black      0.506197   \n",
       "8  0.441750  0.553171  psychiatric_or_mental_illness      0.523564   \n",
       "\n",
       "   subgroup_size  \n",
       "0          16117  \n",
       "5           5200  \n",
       "1          14774  \n",
       "2           3034  \n",
       "3          12325  \n",
       "7           6094  \n",
       "4           2079  \n",
       "6           3961  \n",
       "8           2057  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME = 'my_model'\n",
    "df_validate[MODEL_NAME] = model.predict(pad_text(df_validate[TEXT_COLUMN], tokenizer))[:, 1]\n",
    "\n",
    "import p9_util_benchmark\n",
    "df_bias_metrics = p9_util_benchmark.compute_bias_metrics_for_model(df_validate, identity_columns, MODEL_NAME, TOXICITY_COLUMN)\n",
    "df_bias_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias score contribution : 0.3640472701244321\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4814985731733033"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_auc = p9_util_benchmark.calculate_overall_auc(df_validate, MODEL_NAME)\n",
    "print(overall_auc)\n",
    "\n",
    "p9_util_benchmark.get_final_metric(df_bias_metrics, overall_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bnsp_auc</th>\n",
       "      <th>bpsn_auc</th>\n",
       "      <th>subgroup</th>\n",
       "      <th>subgroup_auc</th>\n",
       "      <th>subgroup_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.858809</td>\n",
       "      <td>0.622410</td>\n",
       "      <td>jewish</td>\n",
       "      <td>0.710941</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.899848</td>\n",
       "      <td>0.536487</td>\n",
       "      <td>black</td>\n",
       "      <td>0.712272</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.893310</td>\n",
       "      <td>0.577209</td>\n",
       "      <td>muslim</td>\n",
       "      <td>0.723871</td>\n",
       "      <td>589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.910689</td>\n",
       "      <td>0.547952</td>\n",
       "      <td>white</td>\n",
       "      <td>0.738688</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.854539</td>\n",
       "      <td>0.655009</td>\n",
       "      <td>female</td>\n",
       "      <td>0.740394</td>\n",
       "      <td>1623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.814839</td>\n",
       "      <td>0.715750</td>\n",
       "      <td>christian</td>\n",
       "      <td>0.747667</td>\n",
       "      <td>1355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.904465</td>\n",
       "      <td>0.569516</td>\n",
       "      <td>homosexual_gay_or_lesbian</td>\n",
       "      <td>0.752778</td>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.822805</td>\n",
       "      <td>0.710397</td>\n",
       "      <td>psychiatric_or_mental_illness</td>\n",
       "      <td>0.755221</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.853071</td>\n",
       "      <td>0.675013</td>\n",
       "      <td>male</td>\n",
       "      <td>0.764639</td>\n",
       "      <td>1750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bnsp_auc  bpsn_auc                       subgroup  subgroup_auc  \\\n",
       "4  0.858809  0.622410                         jewish      0.710941   \n",
       "6  0.899848  0.536487                          black      0.712272   \n",
       "5  0.893310  0.577209                         muslim      0.723871   \n",
       "7  0.910689  0.547952                          white      0.738688   \n",
       "1  0.854539  0.655009                         female      0.740394   \n",
       "3  0.814839  0.715750                      christian      0.747667   \n",
       "2  0.904465  0.569516      homosexual_gay_or_lesbian      0.752778   \n",
       "8  0.822805  0.710397  psychiatric_or_mental_illness      0.755221   \n",
       "0  0.853071  0.675013                           male      0.764639   \n",
       "\n",
       "   subgroup_size  \n",
       "4            229  \n",
       "6            415  \n",
       "5            589  \n",
       "7            655  \n",
       "1           1623  \n",
       "3           1355  \n",
       "2            306  \n",
       "8            221  \n",
       "0           1750  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import p9_util_benchmark\n",
    "df_bias_metrics = p9_util_benchmark.compute_bias_metrics_for_model(df_validate, identity_columns, MODEL_NAME, TOXICITY_COLUMN)\n",
    "df_bias_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7831349797714786"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_auc = p9_util_benchmark.calculate_overall_auc(df_validate, MODEL_NAME)\n",
    "overall_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias score contribution : 0.5512879262998152\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7470716712426848"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p9_util_benchmark.get_final_metric(df_bias_metrics, overall_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bnsp_auc</th>\n",
       "      <th>bpsn_auc</th>\n",
       "      <th>subgroup</th>\n",
       "      <th>subgroup_auc</th>\n",
       "      <th>subgroup_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.893172</td>\n",
       "      <td>0.455094</td>\n",
       "      <td>muslim</td>\n",
       "      <td>0.625448</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.866740</td>\n",
       "      <td>0.568029</td>\n",
       "      <td>homosexual_gay_or_lesbian</td>\n",
       "      <td>0.664032</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.908445</td>\n",
       "      <td>0.528858</td>\n",
       "      <td>jewish</td>\n",
       "      <td>0.693135</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.926768</td>\n",
       "      <td>0.482684</td>\n",
       "      <td>white</td>\n",
       "      <td>0.695527</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.860868</td>\n",
       "      <td>0.610430</td>\n",
       "      <td>female</td>\n",
       "      <td>0.697728</td>\n",
       "      <td>515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.840209</td>\n",
       "      <td>0.650368</td>\n",
       "      <td>christian</td>\n",
       "      <td>0.710166</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.908605</td>\n",
       "      <td>0.554461</td>\n",
       "      <td>black</td>\n",
       "      <td>0.718285</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.865677</td>\n",
       "      <td>0.624584</td>\n",
       "      <td>male</td>\n",
       "      <td>0.729710</td>\n",
       "      <td>552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.868687</td>\n",
       "      <td>0.671004</td>\n",
       "      <td>psychiatric_or_mental_illness</td>\n",
       "      <td>0.744697</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bnsp_auc  bpsn_auc                       subgroup  subgroup_auc  \\\n",
       "5  0.893172  0.455094                         muslim      0.625448   \n",
       "2  0.866740  0.568029      homosexual_gay_or_lesbian      0.664032   \n",
       "4  0.908445  0.528858                         jewish      0.693135   \n",
       "7  0.926768  0.482684                          white      0.695527   \n",
       "1  0.860868  0.610430                         female      0.697728   \n",
       "3  0.840209  0.650368                      christian      0.710166   \n",
       "6  0.908605  0.554461                          black      0.718285   \n",
       "0  0.865677  0.624584                           male      0.729710   \n",
       "8  0.868687  0.671004  psychiatric_or_mental_illness      0.744697   \n",
       "\n",
       "   subgroup_size  \n",
       "5            179  \n",
       "2            100  \n",
       "4             70  \n",
       "7            226  \n",
       "1            515  \n",
       "3            381  \n",
       "6            151  \n",
       "0            552  \n",
       "8             74  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import p9_util_benchmark\n",
    "df_bias_metrics = p9_util_benchmark.compute_bias_metrics_for_model(df_validate, identity_columns, MODEL_NAME, TOXICITY_COLUMN)\n",
    "df_bias_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7869874012801156"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_auc = p9_util_benchmark.calculate_overall_auc(df_validate, MODEL_NAME)\n",
    "overall_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias score contribution : 0.5291632672606412\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7259101175806701"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p9_util_benchmark.get_final_metric(df_bias_metrics, overall_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark model considering number of samples for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000, 11000]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME = 'my_model'\n",
    "n_sample = 1000\n",
    "list_i_sample=[i_sample for i_sample in range(n_sample,df_validate.shape[0], n_sample)]\n",
    "list_i_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias score contribution : 0.5146468627064191\n",
      "Bias score contribution : 0.5311479703229279\n",
      "Bias score contribution : 0.5531618796000058\n",
      "Bias score contribution : 0.5341103982806941\n",
      "Bias score contribution : 0.5352761914396593\n",
      "Bias score contribution : 0.540778956436581\n",
      "Bias score contribution : 0.5518264065450231\n",
      "Bias score contribution : 0.549252664069153\n",
      "Bias score contribution : 0.5451565086022001\n",
      "Bias score contribution : 0.5492753276817949\n",
      "Bias score contribution : 0.5490391185560244\n"
     ]
    }
   ],
   "source": [
    "dict_final_metric = dict()\n",
    "for i_sample in list_i_sample:\n",
    "    print(0,i_sample, end='\\r')\n",
    "\n",
    "    df_validate_sample = df_validate.iloc[0:i_sample]\n",
    "    df_validate_sample[MODEL_NAME] = \\\n",
    "    model.predict(pad_text(df_validate_sample[TEXT_COLUMN], tokenizer))[:, 1]\n",
    "\n",
    "    df_bias_metrics = p9_util_benchmark.compute_bias_metrics_for_model(df_validate_sample, identity_columns, MODEL_NAME, TOXICITY_COLUMN)\n",
    "\n",
    "    overall_auc = p9_util_benchmark.calculate_overall_auc(df_validate_sample, MODEL_NAME)\n",
    "\n",
    "    dict_final_metric[i_sample] = p9_util_benchmark.get_final_metric(df_bias_metrics, overall_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000     0.716296\n",
       "2000     0.731172\n",
       "3000     0.751949\n",
       "4000     0.732136\n",
       "5000     0.731803\n",
       "6000     0.737424\n",
       "7000     0.748801\n",
       "8000     0.745725\n",
       "9000     0.741739\n",
       "10000    0.746510\n",
       "11000    0.746110\n",
       "dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser_final_metric = pd.Series(dict_final_metric)\n",
    "ser_final_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# gca stands for 'get current axis'\n",
    "ax = plt.gca()\n",
    "\n",
    "ser_final_metric.plot(kind='line',ax=ax, title=\"Bias score= F(samples)\", x='samples')\n",
    "#ser_final_metric.plot(kind='line',x='name',y='num_pets', color='red', ax=ax)\n",
    "ax.set_xlabel('Texts for validation', color='b')\n",
    "ax.set_ylabel('Score', color='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1008 10:22:58.903397 140393805576000 deprecation_wrapper.py:119] From /home/bangui/anaconda3/envs/python36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1008 10:22:58.990973 140393805576000 deprecation_wrapper.py:119] From /home/bangui/anaconda3/envs/python36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1008 10:22:59.023194 140393805576000 deprecation_wrapper.py:119] From /home/bangui/anaconda3/envs/python36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W1008 10:22:59.188047 140393805576000 deprecation_wrapper.py:119] From /home/bangui/anaconda3/envs/python36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:131: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1008 10:22:59.189996 140393805576000 deprecation_wrapper.py:119] From /home/bangui/anaconda3/envs/python36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W1008 10:22:59.214293 140393805576000 deprecation.py:506] From /home/bangui/anaconda3/envs/python36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1008 10:22:59.715459 140393805576000 deprecation_wrapper.py:119] From /home/bangui/anaconda3/envs/python36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W1008 10:23:01.142762 140393805576000 deprecation_wrapper.py:119] From /home/bangui/anaconda3/envs/python36/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p5_util.object_load : fileName= ./data/benchmark/tokenizer_FULL.dill\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import p5_util\n",
    "filename_model = './data/benchmark/model_jigsaw_benchmark_sampleFULL_threshold0.1.h5'\n",
    "model = keras.models.load_model(filename_model)\n",
    "\n",
    "filename_tokenizer = './data/benchmark/tokenizer_FULL.dill'\n",
    "tokenizer = p5_util.object_load(filename_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 250, 300)          105909900 \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 250, 256)          230656    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 25, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 25, 256)           262400    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 3, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 3, 256)            327936    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 1, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 1, 256)            393472    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 1, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 107,157,518\n",
      "Trainable params: 1,247,618\n",
      "Non-trainable params: 105,909,900\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "if True :\n",
    "    df_test = pd.read_csv('./data/test.csv.zip', compression='zip', header=0, sep=',', quotechar='\"')\n",
    "    submission = pd.read_csv('./sample_submission.csv', index_col='id')\n",
    "\n",
    "    submission['prediction'] = model.predict(pad_text(df_test[TEXT_COLUMN], tokenizer))[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('./data/benchmark/submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
